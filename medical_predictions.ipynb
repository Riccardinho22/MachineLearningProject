{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Month Death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "file = open(\"pickle/1MD/1MD_imputation.pkl\",'rb')\n",
    "dataset = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ----------  init features selection----------\n",
    "from ProjectML.monthDeath.pre_processing import *\n",
    "from ProjectML.monthDeath.feature_extraction import *\n",
    "X, y, dataset = extract_feature(dataset)\n",
    "X = drop_corr_feature(X, 0.6)\n",
    "X = best_eight_features(X)\n",
    "# ----------  end features selection----------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "file = open(\"pickle/1MD/model_xgb.pkl\",'rb')\n",
    "xgb = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# evaluation\n",
    "from ProjectML.general_util.evaluation import *\n",
    "print(\"Cross validation cv = 5 \")\n",
    "balanced_accuracy_score = get_balanced_accuracy(X, y, xgb)\n",
    "print(\"Balanced accuracy: %0.2f (+/- %0.2f)\" % (balanced_accuracy_score.mean(), balanced_accuracy_score.std() * 2))\n",
    "f1_score = get_f1_scores(X, y, xgb)\n",
    "print(\"f1_score: %0.2f (+/- %0.2f)\" % (f1_score.mean(), f1_score.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procedural Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "file2 = open(\"pickle/PS/PS_imputation.pkl\",'rb')\n",
    "dataset = pickle.load(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ----------  load datasets ----------\n",
    "from ProjectML.proceduralSuccess.pre_processing import *\n",
    "from ProjectML.proceduralSuccess.feature_extraction import *\n",
    "X, y, dataset = extract_feature(dataset)\n",
    "mask, gb_coefs, gb_mask, rf_coefs, rf_mask = voting_feature_selection(X, y)\n",
    "X = X.loc[:,mask]\n",
    "\n",
    "X_scaled = pd.read_pickle('pickle/PS/PS_scaled_features.pkl')\n",
    "X_scaled = X_scaled.loc[:, ['CenterID','PatientID']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "file2 = open(\"pickle/PS/model_random_forest.pkl\",'rb')\n",
    "rf= pickle.load(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- init split test ----------\n",
    "X_train_val, X_test, y_train_val, y_test = my_l_split(X, y, 0.1)\n",
    "X_train_val_scal, X_test_scal, y_train_val_scal, y_test_scal = my_l_split(X_scaled, y, 0.1)\n",
    "# ---------- end split test ----------\n",
    "\n",
    "\n",
    "# ---------- init split train validation ----------\n",
    "X_train, X_val, y_train, y_val = my_l_split(X_train_val, y_train_val, 2 / 9)\n",
    "X_train_scal, X_val_scal, y_train_scal, y_val_scal = my_l_split(X_train_val_scal, y_train_val_scal, 2 / 9)\n",
    "# ---------- end split train validation ----------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation\n",
    "from ProjectML.general_util.evaluation import *\n",
    "print(\"Classification report on test set:\")\n",
    "y_pred = rf.predict(X_test)\n",
    "rep_test = classification_report(y_test, y_pred)\n",
    "print(rep_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation f1 score\n",
    "clf = RandomForestClassifier(n_estimators=500, criterion='gini', max_features=5, n_jobs=-1, \\\n",
    "                             class_weight='balanced',random_state=SEED)\n",
    "print(\"Cross validation cv = 10 \")\n",
    "f1_mean0, f1_std0, f1_mean1, f1_std1 = my_cross_f1(X, y, clf, cv=10)\n",
    "print(\"f1_score: %0.2f (+/- %0.2f) (class 0)\" % (f1_mean0, f1_std0 * 1.95))\n",
    "print(\"f1_score: %0.2f (+/- %0.2f) (class 1)\" % (f1_mean1, f1_std1 * 1.95))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "file2 = open(\"pickle/PS/model_svm.pkl\",'rb')\n",
    "svm= pickle.load(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ProjectML.general_util.evaluation import *\n",
    "print(\"Classification report on test set:\")\n",
    "y_pred = svm.predict(X_test_scal)\n",
    "rep_test = classification_report(y_test_scal, y_pred)\n",
    "print(rep_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation f1 score\n",
    "clf = svm.SVC(C=100.0, kernel='rbf', class_weight='balanced', max_iter=-1, random_state=SEED)\n",
    "print(\"SVM: cross validation cv = 10 \")\n",
    "f1_mean0, f1_std0, f1_mean1, f1_std1 = my_cross_f1(X_scaled, y, clf, cv=10)\n",
    "print(\"f1_score: %0.2f (+/- %0.2f) (class 0)\" % (f1_mean0, f1_std0 * 1.95))\n",
    "print(\"f1_score: %0.2f (+/- %0.2f) (class 1)\" % (f1_mean1, f1_std1 * 1.95))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
